{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/Lenna.png\")\n",
    "cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"Lenna2.jpg\", img)\n",
    "#cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/Lenna.png\", 1) #1 means load the image with its original channels\n",
    "#img = cv2.imread(\"Lenna.png\", 0) #0 means load the image in black and white\n",
    "print(\"img\", img)\n",
    "print(img[:,:,0])\n",
    "print(img[0,0,:])\n",
    "print(\"Image type\", type(img))\n",
    "print(\"Image type\", img.dtype)\n",
    "print(\"Image size\", img.shape)\n",
    "print(\"Image size\", len(img), len(img[0]), len(img[0][0]))\n",
    "print(\"# of pixels multiplied by # of channels\", img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBlack = np.zeros([150, 200, 1], 'uint8')\n",
    "cv2.imshow(\"Black\", imgBlack)\n",
    "print(imgBlack[0][0][:])\n",
    "\n",
    "imgOnes = np.ones([150, 200, 3], 'uint8')\n",
    "cv2.imshow(\"Ones\", imgOnes)\n",
    "print(imgOnes[0][0][:])\n",
    "\n",
    "imgWhite = np.ones([150, 200, 3], 'uint16')\n",
    "imgWhite *= (2**16 - 1)\n",
    "cv2.imshow(\"White\", imgWhite)\n",
    "print(imgWhite[0][0][:])\n",
    "\n",
    "imgBlue = imgOnes.copy()\n",
    "imgBlue[:,:] = (255, 0, 0)\n",
    "cv2.imshow(\"Blue\", imgBlue)\n",
    "print(imgBlue[0][0][:])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/Lenna.png\", 1)\n",
    "cv2.imshow(\"Img\", img)\n",
    "cv2.moveWindow(\"Img\", 0, 0)\n",
    "print(img.shape)\n",
    "height, width, channels = img.shape\n",
    "\n",
    "b, g, r = cv2.split(img)\n",
    "imgBGR = np.empty([height, width * 3], 'uint8')\n",
    "imgBGR[:,0:width] = b #cv2.merge(b)\n",
    "imgBGR[:,width:width*2] = g #cv2.merge(g)\n",
    "imgBGR[:,width*2:width*3] = r #cv2.merge(r)\n",
    "cv2.imshow(\"BGR\", imgBGR)\n",
    "cv2.moveWindow(\"BGR\", 0, height)\n",
    "\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(imgHSV)\n",
    "imgHSVSplit = np.concatenate((h, s, v), axis = 1)\n",
    "cv2.imshow(\"HSV Split\", imgHSVSplit)\n",
    "cv2.moveWindow(\"HSV Split\", 0, 0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/RGB.png\", 1)\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite(\"RGB Gray.jpg\", imgGray)\n",
    "\n",
    "b = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "r = img[:,:,2]\n",
    "imgBGRA = cv2.merge((b, g, r, b))\n",
    "cv2.imwrite(\"RGB Blue Transparent.png\", imgBGRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/Lenna.png\")\n",
    "cv2.imshow(\"Img\", img)\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(img, (55, 5), 0) #blur more on x axis\n",
    "cv2.imshow(\"Blur\", imgBlur)\n",
    "\n",
    "kernel = np.ones((5,5), 'uint8')\n",
    "imgDilate = cv2.dilate(img, kernel, iterations = 1)\n",
    "imgErode = cv2.erode(img, kernel, iterations = 1)\n",
    "cv2.imshow(\"Dilate\", imgDilate)\n",
    "cv2.imshow(\"Erode\", imgErode)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../Resources/Images/Lenna.png\")\n",
    "cv2.imshow(\"Img\", img)\n",
    "\n",
    "#Scale\n",
    "imgHalf = cv2.resize(img, (0, 0), fx = 0.5, fy = 0.5)\n",
    "imgStretch = cv2.resize(img, (800, 800))\n",
    "imgStretchNear = cv2.resize(img, (800, 800), interpolation = cv2.INTER_NEAREST)\n",
    "cv2.imshow(\"imgHalf\", imgHalf)\n",
    "cv2.imshow(\"imgStretch\", imgStretch)\n",
    "cv2.imshow(\"imgStretchNear\", imgStretchNear)\n",
    "\n",
    "#Rotation\n",
    "matrix = cv2.getRotationMatrix2D((0,0), -30, 1)\n",
    "imgRotate = cv2.warpAffine(img, matrix, (img.shape[1], img.shape[0]))\n",
    "cv2.imshow(\"imgRotate\", imgRotate)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "color = (0, 255, 0)\n",
    "lineWidth = 3\n",
    "radius = 100\n",
    "point = (0, 0)\n",
    "\n",
    "def click(event, x, y, flag, param):\n",
    "    global point, pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"pressed\", x, y)\n",
    "        point = (x, y)\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", click)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #frame = cv2.resize(frame, (0, 0), fx = 0.5, fy = 0.5)\n",
    "    cv2.circle(frame, point, radius, color, lineWidth)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simple drawing app\n",
    "import numpy as np\n",
    "import cv2\n",
    "canvas = np.ones([500, 500, 3], 'uint8')*255\n",
    "\n",
    "color = (0, 255, 0)\n",
    "radius = 3\n",
    "pressed = False\n",
    "\n",
    "def click(event, x, y, flag, param):\n",
    "    global canvas, pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pressed = True\n",
    "        cv2.circle(canvas, (x, y), radius, color, -1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and pressed == True:\n",
    "        cv2.circle(canvas, (x, y), radius, color, -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        pressed = False\n",
    "        \n",
    "cv2.namedWindow(\"Canvas\")\n",
    "cv2.setMouseCallback(\"Canvas\", click)\n",
    "while True:\n",
    "    \n",
    "    #cv2.circle(frame, point, radius, color, lineWidth)\n",
    "    cv2.imshow(\"Canvas\", canvas)\n",
    "    \n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif ch & 0xFF == ord('b'):\n",
    "        color = (255, 0, 0)\n",
    "    elif ch & 0xFF == ord('g'):\n",
    "        color = (0, 255, 0)\n",
    "    elif ch & 0xFF == ord('r'):\n",
    "        color = (0, 0, 255)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholding\n",
    "img = cv2.imread(\"../Resources/Images/Lenna.png\", 0)\n",
    "height, width = img.shape[0:2]\n",
    "imgBinary = np.zeros([height, width, 1], 'uint8')\n",
    "threshold = 85\n",
    "for row in range(0, height):\n",
    "    for col in range(0, width):\n",
    "        if img[row][col] > threshold:\n",
    "            imgBinary[row][col] = 255\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Slow Biary\", imgBinary)\n",
    "\n",
    "ret, imgThreshold = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"CV2 Biary\", imgThreshold)\n",
    "\n",
    "imgAdaptiveThreshold = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
    "cv2.imshow(\"CV2 Adaptive Threshold\", imgAdaptiveThreshold)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skin Detection\n",
    "img = cv2.imread(\"../Resources/Images/faces.jpeg\")\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h = imgHSV[:,:,0]\n",
    "s = imgHSV[:,:,1]\n",
    "v = imgHSV[:,:,2]\n",
    "imgHSVSplit = np.concatenate((h, s, v), axis = 1)\n",
    "cv2.imshow(\"HSV Split\", cv2.resize(imgHSVSplit, (0, 0), fx = 0.1, fy = 0.1))\n",
    "\n",
    "ret, imgMinSat = cv2.threshold(s, 40, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Min Sat\", cv2.resize(imgMinSat, (0, 0), fx = 0.1, fy = 0.1))\n",
    "\n",
    "ret, imgMaxHue = cv2.threshold(h, 15, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Max Hue\", cv2.resize(imgMaxHue, (0, 0), fx = 0.1, fy = 0.1))\n",
    "\n",
    "imgThreshold = cv2.bitwise_and(imgMinSat, imgMaxHue)\n",
    "cv2.imshow(\"Final\", cv2.resize(imgThreshold, (0, 0), fx = 0.1, fy = 0.1))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contour Object Detection\n",
    "img = cv2.imread(\"../Resources/Images/detect_blob.png\", 1)\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "imgThreshold = cv2.adaptiveThreshold(imgGray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
    "cv2.imshow(\"Threshold Image\", imgThreshold)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "imgCopy = img.copy()\n",
    "index = -1\n",
    "color = (255, 0, 255)\n",
    "thickness = 4\n",
    "\n",
    "cv2.drawContours(imgCopy, contours, index, color, thickness)\n",
    "cv2.imshow(\"Contours\", imgCopy)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area, Perimeter, Center and Curvature\n",
    "img = cv2.imread(\"../Resources/Images/detect_blob.png\", 1)\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "imgThreshold = cv2.adaptiveThreshold(imgGray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
    "cv2.imshow(\"Threshold Image\", imgThreshold)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "imgCopy = img.copy()\n",
    "index = -1\n",
    "color = (255, 0, 255)\n",
    "thickness = 4\n",
    "objects = np.zeros([img.shape[0], img.shape[1], 3], 'uint8')\n",
    "for c in contours:\n",
    "    cv2.drawContours(objects, [c], -1, color, -1)\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c, True) #True means that the arc is a closed loop/contour\n",
    "    \n",
    "    #draw centroid of the contour\n",
    "    #1. calculating the moment of the image/contour\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.circle(objects, (cx, cy), 4, (0, 0, 255), -1)\n",
    "    print(\"Area: {}, perimeter: {}\".format(area, perimeter))\n",
    "cv2.imshow(\"Contours\", objects)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canny Edge Detection\n",
    "img = cv2.imread(\"../Resources/Images/Lenna.png\", 1)\n",
    "\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "res, imgThreshold = cv2.threshold(imgHSV[:,:,0], 115, 255, cv2.THRESH_BINARY_INV) #hue less than 25\n",
    "cv2.imshow(\"Threshold\", imgThreshold)\n",
    "\n",
    "imgEdge = cv2.Canny(img, 100, 70)\n",
    "cv2.imshow(\"Canny Image\", imgEdge)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area: 113971.5, perimeter: 4284.769007444382\n",
      "Area: 5203.5, perimeter: 311.5807340145111\n",
      "Area: 30571.0, perimeter: 809.4701238870621\n",
      "Area: 1607.0, perimeter: 1402.361600637436\n",
      "Area: 17803.0, perimeter: 569.622364282608\n"
     ]
    }
   ],
   "source": [
    "#Challenge: Assign Object ID and Attributes\n",
    "import random\n",
    "\n",
    "img = cv2.imread(\"../Resources/Images/fuzzy.png\", 1)\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (3, 3), 0) #blur more on x axis\n",
    "imgThreshold = cv2.adaptiveThreshold(imgBlur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 205, 1)\n",
    "cv2.imshow(\"Threshold Image\", imgThreshold)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "objects = np.zeros([img.shape[0], img.shape[1], 3], 'uint8')\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c, True) #True means that the arc is a closed loop/contour\n",
    "    if area > 1000:\n",
    "        color = (random.randint(0,255),random.randint(0,255),random.randint(0,255))\n",
    "        cv2.drawContours(objects, [c], -1, color, -1)\n",
    "        print(\"Area: {}, perimeter: {}\".format(area, perimeter))\n",
    "cv2.imshow(\"Contours\", objects)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4659745395183563 (132, 243)\n"
     ]
    }
   ],
   "source": [
    "#Template Matching\n",
    "img = cv2.imread(\"../Resources/Images/players.jpg\", 0)\n",
    "imgTemplate = cv2.imread(\"../Resources/Images/template.jpg\", 0)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Template\", imgTemplate)\n",
    "\n",
    "imgMatched = cv2.matchTemplate(img, imgTemplate, cv2.TM_CCOEFF_NORMED)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(imgMatched)\n",
    "print(max_val, max_loc)\n",
    "cv2.circle(imgMatched, max_loc, 15, 255, 2)\n",
    "cv2.imshow(\"Result\", imgMatched)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CascadeClassifier 000001A1E6218A50>\n",
      "Number of Detected Faces 25\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"../Resources/Images/faces.jpeg\", 1)\n",
    "img = cv2.resize(img, (0, 0), fx = 0.25, fy = 0.25)\n",
    "path = \"../Resources/Haar Cascades/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Faces\", imgGray)\n",
    "faceCascade = cv2.CascadeClassifier(path)\n",
    "print(faceCascade)\n",
    "#faces = faceCascade.detectMultiScale(imgGray, scaleFactor = 1.05, minNeighbors = 5, minSize = (40, 40))\n",
    "faces = faceCascade.detectMultiScale(imgGray, scaleFactor = 1.10, minNeighbors = 5, minSize = (40, 40))\n",
    "print(\"Number of Detected Faces: \", len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imshow(\"Faces\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Detected Eyes:  42\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"../Resources/Images/faces.jpeg\", 1)\n",
    "img = cv2.resize(img, (0, 0), fx = 0.25, fy = 0.25)\n",
    "path = \"../Resources/Haar Cascades/haarcascade_eye.xml\"\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow(\"Faces\", imgGray)\n",
    "faceCascade = cv2.CascadeClassifier(path)\n",
    "#faces = faceCascade.detectMultiScale(imgGray, scaleFactor = 1.03, minNeighbors = 10, minSize = (5, 5))\n",
    "faces = faceCascade.detectMultiScale(imgGray, scaleFactor = 1.02, minNeighbors = 20, minSize = (10, 10))\n",
    "print(\"Number of Detected Eyes: \", len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.circle(img, (int(x + w/2), int(y + h/2)), 15, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Eyes\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
