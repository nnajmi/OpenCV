{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('Lenna.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and showing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Lenna.png')\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0) #adding delay, 0 is infite delay and 1000 is 1 sec delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and showing a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is an error at the end\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"carVideo3.mp4\")\n",
    "while cap.isOpened():\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img, (400, 400))\n",
    "    cv2.imshow(\"Video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and showing from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #Width\n",
    "cap.set(4, 480) #Height\n",
    "cap.set(10, 100) #Brightness\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('Lenna.png')\n",
    "cv2.imshow(\"Image\", img)\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "#Gaussian blur can be used on color or gray image\n",
    "imgBlur = cv2.GaussianBlur(img, (7, 7), 0) #second argument is the size of kernel, the third argument is sigmaX\n",
    "cv2.imshow(\"Blur Image\", imgBlur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge Detection\n",
    "imgCanny = cv2.Canny(img, 100, 100) #second and third arguments are the thresholds\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "imgDilation = cv2.dilate(imgCanny, kernel, iterations = 1)\n",
    "cv2.imshow(\"Dilation Image\", imgDilation)\n",
    "imgEroded = cv2.erode(imgDilation, kernel, iterations = 1)\n",
    "cv2.imshow(\"Eroded Image\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize and Crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('Lenna.png')\n",
    "print(img.shape)\n",
    "cv2.imshow(\"Image\", img)\n",
    "imgResized = cv2.resize(img, (250,250))\n",
    "cv2.imshow(\"Resized Image\", imgResized)\n",
    "imgCropped = img[0:250, 250:500]\n",
    "cv2.imshow(\"Cropped Image\", imgCropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapes and texts on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#img = np.zeros((512, 512))\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "print(img.shape)\n",
    "#img[:] = (255, 0, 0)\n",
    "img[100:200, 200:300] = (255, 0, 0)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "#draw lines\n",
    "cv2.line(img, (0, 0), (200, 200), (255, 0, 0), 5) #1st argumet:starting point, 2nd: ending point, 3rd: color, 4th:thickness\n",
    "cv2.line(img, (img.shape[1], 0), (0, img.shape[0]), (0, 255, 0), 2)\n",
    "#draw rectangle\n",
    "cv2.rectangle(img, (100, 100), (300, 300), (0, 0, 255), 2)\n",
    "cv2.rectangle(img, (400, 400), (500, 500), (0, 0, 255), cv2.FILLED) \n",
    "#draw circle\n",
    "cv2.circle(img, (400, 100), 50, (255, 255, 0), 2)\n",
    "#write text\n",
    "cv2.putText(img, \"OPENCV\", (200, 470), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150, 0), 3) #5th argument is the scale, last one is the thickness\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"cards.jpg\")\n",
    "width = 130\n",
    "height = 160\n",
    "pt1 = np.float32([[205, 117], [329, 144], [94, 271], [230, 306]])\n",
    "pt2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "matrix = cv2.getPerspectiveTransform(pt1, pt2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Output Image\", imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Lenna.png\")\n",
    "imgHor = np.hstack((img, img))\n",
    "imgVer = np.vstack((img, img))\n",
    "cv2.imshow(\"Horizontal Image\", imgHor)\n",
    "cv2.imshow(\"Vertical Image\", imgVer)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Lenna.png\")\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"HSV Image\", imgHSV)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def empty(a):\n",
    "    pass\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue Min\", \"TrackBars\", 97, 179, empty)\n",
    "cv2.createTrackbar(\"Hue Max\", \"TrackBars\", 158, 179, empty)\n",
    "cv2.createTrackbar(\"Sat Min\", \"TrackBars\", 67, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Max\", \"TrackBars\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val Min\", \"TrackBars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Val Max\", \"TrackBars\", 255, 255, empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(\"Lenna.png\")\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\", \"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "    print(h_min, h_max, s_min, s_max, v_min, v_max)\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    imgResult = cv2.bitwise_and(img, img, mask = mask)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"HSV Image\", imgHSV)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contours and shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def getContours(img):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #the 2nd argument finds the outer contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area > 60):\n",
    "            print(area)\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 255, 255), 1)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            print(len(approx))\n",
    "            objCor = len(approx) #number of conners for each object \n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            if objCor == 3:\n",
    "                objectType = \"Tri\"\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w / float(h)\n",
    "                if aspRatio > 0.80 and aspRatio < 1.20:\n",
    "                    objectType = \"Squ\"\n",
    "                else:\n",
    "                    objectType = \"Rec\"\n",
    "            elif objCor == 5:\n",
    "                objectType = \"Pen\"\n",
    "            elif objCor == 6:\n",
    "                objectType = \"Hex\"\n",
    "            else:\n",
    "                aspRatio = w / float(h)\n",
    "                if aspRatio > 0.90 and aspRatio < 1.10:\n",
    "                    objectType = \"Cir\"\n",
    "                else:\n",
    "                    objectType = \"Ova\"\n",
    "            cv2.putText(imgContour, objectType, (x + (w // 2), y + (h // 2)), cv2.FONT_HERSHEY_COMPLEX, 1,\n",
    "                        (0, 0 ,0), 1)\n",
    "            \n",
    "            \n",
    "img = cv2.imread(\"shapes3.png\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7, 7), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, 10, 10)\n",
    "imgContour = img.copy()\n",
    "getContours(imgCanny)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.imshow(\"Blur Image\", imgBlur)\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.imshow(\"Contours\", imgContour)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"Lenna.png\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
